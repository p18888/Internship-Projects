{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bs4\n",
    "import requests\n",
    "from bs4 import BeautifulSoup as soup\n",
    "from urllib.request import urlopen\n",
    "from urllib import request\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Write a python program to display all the header tags from ‘en.wikipedia.org/wiki/Main_Page’."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "link_url='https://en.wikipedia.org/wiki/Main_Page'\n",
    "url=urlopen(link_url)\n",
    "data=soup(url,'html.parser')\n",
    "data.findAll('head')\n",
    "for i in data.findAll('head'):\n",
    "    print(i.title.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Write a python program to display IMDB’s Top rated 100 movies’ data (i.e. Name, IMDB rating, Year of release) and save it in form of a CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "page=requests.get('https://www.imdb.com/list/ls091520106/')\n",
    "print(page)\n",
    "data=soup(page.content,'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open('Top 100 Movies list.csv','w') as file:\n",
    "    file.write(\"Movie Name,Release Year,Movie Rating,\")\n",
    "    file.write('\\n')\n",
    "    for i,j,k in zip(data.find_all('h3',class_='lister-item-header'),data.find_all('span',class_='lister-item-year text-muted unbold'),data.find_all('div',class_='ipl-rating-star small')):\n",
    "        if len(i.a.text.split(','))>1:\n",
    "            i=i.a.text.replace(',','')\n",
    "        else:\n",
    "            i=i.a.text     \n",
    "        values=i,j.text.strip('()'),k.find('span',class_='ipl-rating-star__rating').text\n",
    "        file.writelines(\"%s,\" % val for val in list(values))\n",
    "        file.write('\\n')\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Write a python program to display IMDB’s Top rated 100 Indian movies’ data (i.e. Name, IMDB rating, Year of release) and save it in form of a CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "page=requests.get('https://www.imdb.com/list/ls009997493/')\n",
    "print(page)\n",
    "data=soup(page.content,'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Top 100 Indian Movies list.csv','w') as file:\n",
    "    file.write(\"Movie Name,Movie Rating,Release Year,\")\n",
    "    file.write('\\n')\n",
    "    for i,j,k in zip(data.find_all('h3',class_='lister-item-header'),data.find_all('div',class_='ipl-rating-star small'),data.find_all('span',class_='lister-item-year text-muted unbold')):\n",
    "        if len(i.a.text.split(','))>1:\n",
    "            i=i.a.text.replace(',','')\n",
    "        else:\n",
    "            i=i.a.text     \n",
    "        values=i,j.find('span',class_='ipl-rating-star__rating').text,k.text.strip('()')\n",
    "        file.writelines(\"%s,\" % val for val in list(values))\n",
    "        file.write('\\n')\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Write a python program to scrap book name, author name, genre and book review of any 5 books from\n",
    "‘www.bookpage.com’"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "page=requests.get('https://bookpage.com/reviews')\n",
    "data=soup(page.content,'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv \n",
    "# opening the csv file in 'w' mode \n",
    "file = open('Books names and author.csv', 'w', newline ='') \n",
    "with file: \n",
    "    # identifying header   \n",
    "    header = ['Book name', 'Author', 'Gener','Review by','Review'] \n",
    "    writer = csv.DictWriter(file, fieldnames = header) \n",
    "    writer.writeheader() \n",
    "    page=requests.get('https://bookpage.com/reviews')\n",
    "    data=soup(page.content,'html.parser')  \n",
    "    # writing data row-wise into the csv file \n",
    "    for i in data.find_all('div',class_='flex-article-content'):\n",
    "        page1=requests.get('https://bookpage.com/'+i.a.get('href'))\n",
    "        data1=soup(page1.content,'html.parser')\n",
    "        for j in data1.find_all('p',class_='sans bold author-info'):\n",
    "            review_by=j.a.text.replace('\\n','')\n",
    "        for k in data1.find_all('p',class_='genre-links'):\n",
    "            gener=k.text.replace('\\n','')\n",
    "        writer.writerow({'Book name' : i.a.text,  \n",
    "                     'Author': i.p.text.replace(\"\\n\",''),  \n",
    "                     'Gener': gener,\n",
    "                     'Review by': review_by,\n",
    "                        'Review':i.find('p',class_='excerpt').text}) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Write a python program to scrape cricket rankings from ‘www.icc-cricket.com’. You have to scrape:\n",
    "i. Top 10 ODI teams in men’s cricket along with the records for matches, points and rating. \n",
    "ii. Top 10 ODI Batsmen in men along with the records of their team and rating. \n",
    "iii. Top 10 ODI bowlers along with the records of their team and rating.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "page=requests.get('https://www.icc-cricket.com/rankings/mens/team-rankings/odi')\n",
    "data=soup(page.content,'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "cr_table = data.find(\"table\", attrs={\"class\": \"table\"})\n",
    "with open(\"Top 20 Men's Cricket teams.csv\", 'w') as f: \n",
    "    # using csv.writer method from CSV package \n",
    "    write = csv.writer(f) \n",
    "    write.writerow(['Pos','Team','Team Short name','Matches','Points','Rating']) \n",
    "    for i in cr_table.tbody.find_all(\"tr\"):\n",
    "        write.writerow([j.replace(' ','') for j in i.text.split('\\n') if j.strip(' ')])\n",
    "f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "page=requests.get('https://www.icc-cricket.com/rankings/mens/player-rankings/odi')\n",
    "data=soup(page.content,'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "cr_table = data.find(\"table\", attrs={\"class\": \"table\"})\n",
    "with open(\"Top 10 Men's ODI Batting Rankings.csv\", 'w') as f: \n",
    "    # using csv.writer method from CSV package \n",
    "    write = csv.writer(f) \n",
    "    write.writerow(cr_table.thead.tr.text.replace('\\n',' ').split())\n",
    "    f_row=[i.strip(' \\n') for i in data.find(\"a\", attrs={\"class\": \"rankings-block__banner-link\"}).text.split('\\n\\n\\n') if i]\n",
    "    f_row.append(data.find(\"div\", attrs={\"class\": \"rankings-block__banner--rating\"}).text)\n",
    "    write.writerow(f_row)\n",
    "    for i in cr_table.tbody.find_all(\"tr\"):\n",
    "        write.writerow([j.replace(' ','') for j in i.text.split('\\n') if j.strip(' ')])\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "lis1=[]\n",
    "lis2=[]\n",
    "final_lis=[]\n",
    "with open(\"Top 10 Men's ODI Batting Rankings.csv\", 'w') as f: \n",
    "    # using csv.writer method from CSV package \n",
    "    write = csv.writer(f) \n",
    "    for i,j in zip(data.find_all(\"table\", attrs={\"class\":\"table\"}),data.find_all(\"div\", attrs={\"class\": \"col-4 col-12-desk touch-scroll-list__element\"})):\n",
    "        lis1.append(i.find_all(\"tr\"))\n",
    "        lis2.append(j.find_all('a'))\n",
    "    for k in lis1[0]:\n",
    "        final_lis.append([j.replace(' ','') for j in k.text.split('\\n') if j.strip(' ') and len(j)<50])\n",
    "    for l in lis2[0]:\n",
    "        a=[j.replace(' ','') for j in l.text.split('\\n') if j.strip(' ') and len(j)<50]\n",
    "        a.append(data.find_all(\"div\", attrs={\"class\": \"rankings-block__banner--rating\"})[1].text)\n",
    "        final_lis.insert(1,a)\n",
    "    write.writerows(final_lis)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "lis1=[]\n",
    "lis2=[]\n",
    "final_lis=[]\n",
    "with open(\"Top 10 Men's ODI Bowling Rankings.csv\", 'w') as f: \n",
    "    # using csv.writer method from CSV package \n",
    "    write = csv.writer(f) \n",
    "    for i,j in zip(data.find_all(\"table\", attrs={\"class\":\"table\"}),data.find_all(\"div\", attrs={\"class\": \"col-4 col-12-desk touch-scroll-list__element\"})):\n",
    "        lis1.append(i.find_all(\"tr\"))\n",
    "        lis2.append(j.find_all('a'))\n",
    "    for k in lis1[1]:\n",
    "        final_lis.append([j.replace(' ','') for j in k.text.split('\\n') if j.strip(' ') and len(j)<50])\n",
    "    for l in lis2[1]:\n",
    "        a=[j.replace(' ','') for j in l.text.split('\\n') if j.strip(' ') and len(j)<50]\n",
    "        a.append(data.find_all(\"div\", attrs={\"class\": \"rankings-block__banner--rating\"})[1].text)\n",
    "        final_lis.insert(1,a)\n",
    "    write.writerows(final_lis)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "lis1=[]\n",
    "lis2=[]\n",
    "final_lis=[]\n",
    "with open(\"Top 10 Men's ODI All-Rounder Rankings.csv\", 'w') as f: \n",
    "    # using csv.writer method from CSV package \n",
    "    write = csv.writer(f) \n",
    "    for i,j in zip(data.find_all(\"table\", attrs={\"class\":\"table\"}),data.find_all(\"div\", attrs={\"class\": \"col-4 col-12-desk touch-scroll-list__element\"})):\n",
    "        lis1.append(i.find_all(\"tr\"))\n",
    "        lis2.append(j.find_all('a'))\n",
    "    for k in lis1[2]:\n",
    "        final_lis.append([j.replace(' ','') for j in k.text.split('\\n') if j.strip(' ') and len(j)<50])\n",
    "    for l in lis2[2]:\n",
    "        a=[j.replace(' ','') for j in l.text.split('\\n') if j.strip(' ') and len(j)<50]\n",
    "        a.append(data.find_all(\"div\", attrs={\"class\": \"rankings-block__banner--rating\"})[1].text)\n",
    "        final_lis.insert(1,a)\n",
    "    write.writerows(final_lis)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write a python program to scrape cricket rankings from ‘www.icc-cricket.com’. You have to scrape:\n",
    "i) Top 10 ODI teams in women’s cricket along with the records for matches, points and rating.\n",
    "ii) Top 10 women’s ODI players along with the records of their team and rating.\n",
    "iii) Top 10 women’s ODI all-rounder along with the records of their team and rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "page=requests.get('https://www.icc-cricket.com/rankings/womens/team-rankings/odi')\n",
    "data=soup(page.content,'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "cr_table = data.find(\"table\", attrs={\"class\": \"table\"})\n",
    "with open(\"Top 20 Women's ODI Rankings.csv\", 'w') as f: \n",
    "    # using csv.writer method from CSV package \n",
    "    write = csv.writer(f) \n",
    "    write.writerow(['Pos','Team','Team Short name','Matches','Points','Rating']) \n",
    "    for i in cr_table.tbody.find_all(\"tr\"):\n",
    "        write.writerow([j.replace(' ','') for j in i.text.split('\\n') if j.strip(' ')])\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "page=requests.get('https://www.icc-cricket.com/rankings/womens/player-rankings/odi')\n",
    "data=soup(page.content,'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "lis1=[]\n",
    "lis2=[]\n",
    "final_lis=[]\n",
    "with open(\"Top 10 Women's ODI Batting Rankings.csv\", 'w') as f: \n",
    "    # using csv.writer method from CSV package \n",
    "    write = csv.writer(f) \n",
    "    for i,j in zip(data.find_all(\"table\", attrs={\"class\":\"table\"}),data.find_all(\"div\", attrs={\"class\": \"col-4 col-12-desk uniform-grid__section touch-scroll-list__element\"})):\n",
    "        lis1.append(i.find_all(\"tr\"))\n",
    "        lis2.append(j.find_all('a'))\n",
    "    for k in lis1[0]:\n",
    "        final_lis.append([j.replace(' ','') for j in k.text.split('\\n') if j.strip(' ') and len(j)<50])\n",
    "    for l in lis2[0]:\n",
    "        a=[j.replace(' ','') for j in l.text.split('\\n') if j.strip(' ') and len(j)<50]\n",
    "        a.append(data.find_all(\"div\", attrs={\"class\": \"rankings-block__banner--rating\"})[1].text)\n",
    "        final_lis.insert(1,a)\n",
    "    write.writerows(final_lis)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "lis1=[]\n",
    "lis2=[]\n",
    "final_lis=[]\n",
    "with open(\"Top 10 Women's ODI Bowling Rankings.csv\", 'w') as f: \n",
    "    # using csv.writer method from CSV package \n",
    "    write = csv.writer(f) \n",
    "    for i,j in zip(data.find_all(\"table\", attrs={\"class\":\"table\"}),data.find_all(\"div\", attrs={\"class\": \"col-4 col-12-desk uniform-grid__section touch-scroll-list__element\"})):\n",
    "        lis1.append(i.find_all(\"tr\"))\n",
    "        lis2.append(j.find_all('a'))\n",
    "    for k in lis1[1]:\n",
    "        final_lis.append([j.replace(' ','') for j in k.text.split('\\n') if j.strip(' ') and len(j)<50])\n",
    "    for l in lis2[1]:\n",
    "        a=[j.replace(' ','') for j in l.text.split('\\n') if j.strip(' ') and len(j)<50]\n",
    "        a.append(data.find_all(\"div\", attrs={\"class\": \"rankings-block__banner--rating\"})[1].text)\n",
    "        final_lis.insert(1,a)\n",
    "    write.writerows(final_lis)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "lis1=[]\n",
    "lis2=[]\n",
    "final_lis=[]\n",
    "with open(\"Top 10 Women's ODI All-Rounder Rankings.csv\", 'w') as f: \n",
    "    # using csv.writer method from CSV package \n",
    "    write = csv.writer(f) \n",
    "    for i,j in zip(data.find_all(\"table\", attrs={\"class\":\"table\"}),data.find_all(\"div\", attrs={\"class\": \"col-4 col-12-desk uniform-grid__section touch-scroll-list__element\"})):\n",
    "        lis1.append(i.find_all(\"tr\"))\n",
    "        lis2.append(j.find_all('a'))\n",
    "    for k in lis1[2]:\n",
    "        final_lis.append([j.replace(' ','') for j in k.text.split('\\n') if j.strip(' ') and len(j)<50])\n",
    "    for l in lis2[2]:\n",
    "        a=[j.replace(' ','') for j in l.text.split('\\n') if j.strip(' ') and len(j)<50]\n",
    "        a.append(data.find_all(\"div\", attrs={\"class\": \"rankings-block__banner--rating\"})[1].text)\n",
    "        final_lis.insert(1,a)\n",
    "    write.writerows(final_lis)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write a python program to scrape details of all the mobile phones under Rs. 20,000 listed on Amazon.in. The scraped data should include Product Name, Price, Image URL and Average Rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "page=requests.get('https://www.amazon.in/s?k=mobile+under+20000&i=electronics&ref=nb_sb_noss_1')\n",
    "data=soup(page.content,'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "with open(\"Mobile phones under Rs. 20,000.csv\", 'w') as f: \n",
    "    # using csv.writer method from CSV package \n",
    "    write = csv.writer(f) \n",
    "    write.writerow(['Product Name','Rating','Price','Image Sourse'])\n",
    "    for i in data.find_all('div',class_='sg-col-inner'):\n",
    "        try:\n",
    "            for k,l,m in zip(i.find_all('div',class_='a-row a-size-small'),i.find_all('span',class_='a-price-whole'),i.find_all('img',class_='s-image')):\n",
    "                vals=i.div.h2.a.span.text,k.span.span.a.i.text,l.text,m['src']\n",
    "                write.writerow(list(vals))\n",
    "        except:\n",
    "            pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Write a python program to extract information about the local weather from the National Weather Service website of USA, https://www.weather.gov/ for the city, San Francisco. You need to extract data about 7 day extended forecast display for the city. The data should include period, short description, temperature and description."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page=requests.get('https://forecast.weather.gov/MapClick.php?lat=37.777120000000025&lon=-122.41963999999996#.YFXe9FkzZuT')\n",
    "data=soup(page.content,'html.parser')\n",
    "page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "with open(\"Extended Forecast for San Francisco.csv\", 'w') as f: \n",
    "    # using csv.writer method from CSV package \n",
    "    write = csv.writer(f) \n",
    "    write.writerow(['Period','Short Description','Temperature','Description'])\n",
    "    for i,j in zip(data.find_all('li',class_='forecast-tombstone'),data.find_all('div',class_='col-sm-10 forecast-text')):\n",
    "        try:\n",
    "            vals=i.div.find_all('p')[0].text,i.div.find_all('p')[2].text,i.div.find_all('p')[3].text,j.text\n",
    "            write.writerow(list(vals))\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Write a python program to scrape ‘software developer’ job listings from ‘Monster.com’. It should include all the jobs listed for the next 5 pages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [403]>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page=requests.get('https://www.monsterindia.com/')\n",
    "data=soup(page.content,'html.parser')\n",
    "page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<html><head>\n",
       "<title>Access Denied</title>\n",
       "</head><body>\n",
       "<h1>Access Denied</h1>\n",
       " \n",
       "You don't have permission to access \"http://www.monsterindia.com/\" on this server.<p>\n",
       "Reference #18.c7fdd417.1616308789.152bbee9\n",
       "</p></body>\n",
       "</html>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
